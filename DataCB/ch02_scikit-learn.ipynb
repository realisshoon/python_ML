{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66914172",
   "metadata": {},
   "source": [
    "# scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ca2d018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\hsgb2\\.conda\\envs\\austin\\lib\\site-packages (0.24.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\hsgb2\\.conda\\envs\\austin\\lib\\site-packages (from scikit-learn) (1.7.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\hsgb2\\.conda\\envs\\austin\\lib\\site-packages (from scikit-learn) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\hsgb2\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn) (1.21.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hsgb2\\.conda\\envs\\austin\\lib\\site-packages (from scikit-learn) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d785c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a15a76",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b7d386",
   "metadata": {},
   "source": [
    "## 붓꽃 품종 예측하기\n",
    "```classification```  지도학습 방법의 하나이다. 다양한 피처와 레이블 데이터로 모델을 학습한 후에 테스트 데이터 세트에서 미지의 레이블을 예측한다.\n",
    "\n",
    "```sklearn.datasets``` 내의 모듈은 사이킷런에서 자체적으로 제공하는 데이터 세트를 생성하는 모듈의 모임이다.\n",
    "\n",
    "```sklearn.tree``` 내의 모듈은 트리 기반 ML알고리즘을 구현한 클래스의 모임이다.\n",
    "\n",
    "```sklearn.model_selection``` 은 학습데이터,검증데이터,예측데이터로 데이터를 분리하거나 최적의 하이퍼파라미터로 평가하기 위한 다양한 모듈의 모임이다.\n",
    "\n",
    "```하이퍼파라미터``` ML알고리즘별로 최적의 학습을 위해 직접 이력하는 파라미터를 통칭한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c55a6f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ab3992b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris target값: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "iris target명: ['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "iris=load_iris() #붓꽃 데이터 세트 로딩\n",
    "iris_data=iris.data #iris 데이터 세트에서 피처만으로 된 데이터\n",
    "iris_label=iris.target #iris 데이터 세트에서 레이블 데이터\n",
    "\n",
    "print('iris target값:', iris_label)\n",
    "print('iris target명:', iris.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "177a4e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df=pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
    "iris_df['label']=iris.target\n",
    "iris_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0307f3d2",
   "metadata": {},
   "source": [
    "``피처``sepal length,sepal width 등이 있다.\n",
    "\n",
    "``label``은 0(Setosa),1(versicolor),2(virginica)를 의미한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baacc8c",
   "metadata": {},
   "source": [
    "### 학습용 데이터와 테스터용 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f760363",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(iris_data,iris_label,test_size=0.2,random_state=11)\n",
    "#train_test_split(피처데이터세트,레이블데이터세트,전체 중에 테스트데이터 세트 비율,난수 발생 값) \n",
    "#난수 발생 값을 지정하지 않으면 수행할 때마다 다른 학습/테스트 용 데이터를 만들 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b57db91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=11)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_clf=DecisionTreeClassifier(random_state=11) #DecisionTreeClassifier객체 생성\n",
    "dt_clf.fit(X_train,y_train) #학습수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60e019f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=dt_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1d4aa3",
   "metadata": {},
   "source": [
    "``정확도``예측 결과가 실제 레이블 값과 얼마나 정확하게 맞는지를 평가하는 지표이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ef2a720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도: 0.9333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test,pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65afcab7",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8335aaa",
   "metadata": {},
   "source": [
    "### 내장된 예제 데이터세트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d0aa5f",
   "metadata": {},
   "source": [
    "```data``` 피처의 데이터 세트\n",
    "\n",
    "```target``` 분류 시 레이블 값, 회귀일 때는 숫자 결괏값 데이터 세트\n",
    "\n",
    "```target_names``` 개별 레이블의 이름\n",
    "\n",
    "```feature_names``` 피처의 이름\n",
    "\n",
    "```DESCR``` 데이터 세트와 각 피처에 대한 설명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c074de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_data=load_iris()\n",
    "print(type(iris_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29608818",
   "metadata": {},
   "source": [
    "``Bunch`` 클래스는 파이썬 딕셔너리 자료형과 유사하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7de3204d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "붓꽃 데이터 세트의 키들: dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n"
     ]
    }
   ],
   "source": [
    "keys=iris_data.keys()\n",
    "print('붓꽃 데이터 세트의 키들:',keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f9b9e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_names의 type: <class 'list'>\n",
      "feature_name의 shape: 4\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "print('feature_names의 type:',type(iris_data.feature_names))\n",
    "print('feature_name의 shape:',len(iris_data.feature_names))\n",
    "print(iris_data.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54b21870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_names 의 type: <class 'numpy.ndarray'>\n",
      "target_names 의 shape: 3\n",
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "print('target_names 의 type:',type(iris_data.target_names))\n",
    "print('target_names 의 shape:',len(iris_data.target_names))\n",
    "print(iris_data.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d3d4a0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data의 type: <class 'numpy.ndarray'>\n",
      "data의 shape: (150, 4)\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n"
     ]
    }
   ],
   "source": [
    "print('data의 type:',type(iris_data.data))\n",
    "print('data의 shape:',iris_data.data.shape)\n",
    "print(iris_data['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02554358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target 의 type: <class 'numpy.ndarray'>\n",
      "target 의 shpae: (150,)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "print('target 의 type:', type(iris_data.target))\n",
    "print('target 의 shpae:', iris_data.target.shape)\n",
    "print(iris_data['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf182ac3",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43257c1",
   "metadata": {},
   "source": [
    "# Model Selection 모듈"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ce4f74",
   "metadata": {},
   "source": [
    "## train_test_split()-학습/테스트 데이터 세트 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a733cab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris=load_iris()\n",
    "dt_clf=DecisionTreeClassifier()\n",
    "train_data=iris.data\n",
    "train_label=iris.target\n",
    "dt_clf.fit(train_data,train_label)\n",
    "\n",
    "pred=dt_clf.predict(train_data)\n",
    "print('예측 정확도:', accuracy_score(train_label,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9089ade5",
   "metadata": {},
   "source": [
    "정확도가 100%인 이유는 이미 학습한 학습 데이터 세트를 기반으로 예측했기 때문이다. 따라서 예측을 수행하는 데이터 세트는 학습을 수행한 학습용 데이터 세트가 아닌 전용의 데이터 세트여야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936b603c",
   "metadata": {},
   "source": [
    "```test_size```전체 데이터에서 테스트 데이터 세트 크기를 얼마로 샘플링할 것인가를 결정한다.(Default:0.25)\n",
    "\n",
    "```train_size```전체 데이터에서 학습용 데이터 세트 크기를 얼마로 샘플링 할 것인가를 결정한다. 하지만 ``test_size parameter``를 통상적으로 사용하기 때문에 잘 사용하지 않는다.\n",
    "\n",
    "```shuffle``` 데이터를 분리하기 전에 미리 섞을지를 결정한다.(Default:True)\n",
    "\n",
    "```trian_test_split()``` 반환 값은 튜플 형태이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "47314e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도:0.9556\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_clf=DecisionTreeClassifier()\n",
    "iris_data=load_iris()\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(iris_data.data,iris_data.target,test_size=0.3,random_state=121)\n",
    "\n",
    "dt_clf.fit(X_train,y_train)\n",
    "pred=dt_clf.predict(X_test)\n",
    "print('예측 정확도:{0:.4f}'.format(accuracy_score(y_test,pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf460312",
   "metadata": {},
   "source": [
    "붓꽃의 데이터는 150개의 데이터로 데이터 양이 크지 않아 전체의 30%는 45개 정도 밖에 되지 않는다. 그래서 알고리즘의 예측 성능을 판단하기에는 적절치 않다. 학습을 위한 데이터의 양을 일정 수준 이상으로 보장하는 것도 중요하지만 학습된 모델에 대해 다양한 데이터를 기반으로 예측 성능을 평가해보는 것도 중요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0267de",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20506119",
   "metadata": {},
   "source": [
    "## 교차검증\n",
    "고정된 학습 데이터와 테스트 데이터로 평가를 하다보면 최적의 성능을 발휘할 수 있도록 편향되게 만들어지는 ```과적합```발생하게 된다. 그래서 해당 테스트 데이터 외에 다른 테스트용 데이터가 들어오면 성능이 저하된다. 이를 방지하기 위해 교차검증을 이용해 다양한 학습과 평가를 수행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c85645",
   "metadata": {},
   "source": [
    "### K 폴드 교차 검증\n",
    "가장 보편적인 교차 검증 기법이며,K개의 데이터 폴드 세트를 만들어서 K번만큼 각 폴드 세트에 학습과 검증 평가를 반복적으로 수행하는 기법이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fad5812d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "붓꽃 데이터 세트 크기: 150\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "iris=load_iris()\n",
    "features=iris.data\n",
    "label=iris.target\n",
    "dt_clf=DecisionTreeClassifier(random_state=156)\n",
    " #붓꽃 데이터 세트와 DecisionTreeClassifier 생성\n",
    "\n",
    "kfold=KFold(n_splits=5) #5개의 폴드 세트로 분리\n",
    "cv_accuracy=[] #폴드 세트별 정확도를 담을 리스트 객체 생성\n",
    "print('붓꽃 데이터 세트 크기:',features.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56259b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#1 교차 검증 정확도 :1.0, 학습 데이터 크기 :120, 검증 데이터 크기:30\n",
      "\n",
      "#1 교차 검증 세트 인덱스:30\n",
      "\n",
      "#2 교차 검증 정확도 :0.9667, 학습 데이터 크기 :120, 검증 데이터 크기:30\n",
      "\n",
      "#2 교차 검증 세트 인덱스:30\n",
      "\n",
      "#3 교차 검증 정확도 :0.8667, 학습 데이터 크기 :120, 검증 데이터 크기:30\n",
      "\n",
      "#3 교차 검증 세트 인덱스:30\n",
      "\n",
      "#4 교차 검증 정확도 :0.9333, 학습 데이터 크기 :120, 검증 데이터 크기:30\n",
      "\n",
      "#4 교차 검증 세트 인덱스:30\n",
      "\n",
      "#5 교차 검증 정확도 :0.7333, 학습 데이터 크기 :120, 검증 데이터 크기:30\n",
      "\n",
      "#5 교차 검증 세트 인덱스:30\n",
      "\n",
      "## 평균 검증 정확도: 0.9\n"
     ]
    }
   ],
   "source": [
    "n_iter=0\n",
    "\n",
    "#KFold 객체의 split()를 호출하면 폴드 별 학습용,검증용 테스트의 row index를 array로 반환\n",
    "for train_index,test_index in kfold.split(features):\n",
    "    X_train,X_test=features[train_index],features[test_index]\n",
    "    y_train,y_test=label[train_index],label[test_index]\n",
    "    #학습 및 예측\n",
    "    dt_clf.fit(X_train,y_train)\n",
    "    pred=dt_clf.predict(X_test)\n",
    "    n_iter +=1\n",
    "    #반복 시마다 정확도 측정\n",
    "    accuracy=np.round(accuracy_score(y_test,pred),4)\n",
    "    train_size=X_train.shape[0]\n",
    "    test_size=X_test.shape[0]\n",
    "    print('\\n#{0} 교차 검증 정확도 :{1}, 학습 데이터 크기 :{2}, 검증 데이터 크기:{3}'\n",
    "          .format(n_iter,accuracy,train_size,test_size))\n",
    "    print('\\n#{0} 교차 검증 세트 인덱스:{1}'.format(n_iter,test_size))\n",
    "    cv_accuracy.append(accuracy)\n",
    "    \n",
    "#개별 iteration별 정확도를 합하여 평균 정확도 계산\n",
    "print('\\n## 평균 검증 정확도:',np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fbcdfc",
   "metadata": {},
   "source": [
    "교차 검증 시마다 검증 세트의 인덱스가 달라짐을 알 수 있고, 검증 세트 인덱스를 보면 교차 검증 시마다 split()함수가 어떻게 인덱스를 할당한지 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab10f30",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacb7da8",
   "metadata": {},
   "source": [
    "### Stratified K 폴드\n",
    "Stratified K 폴드는 불균형한 분포도(편향적인 분포도)를 가진 레이블 데이터 집합을 위한 K폴드 방식이다. Stratified K 폴드는 K폴드가 제대로 분배하지 못하는 경우의 문제를 해결해 준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1fd989eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    50\n",
       "1    50\n",
       "2    50\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "iris=load_iris()\n",
    "iris_df=pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "iris_df['label']=iris.target\n",
    "iris_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "094c928e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 교차 검증 :1\n",
      "학습 레이블 데이터 분포:\n",
      " 1    50\n",
      "2    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 0    50\n",
      "Name: label, dtype: int64\n",
      "## 교차 검증 :2\n",
      "학습 레이블 데이터 분포:\n",
      " 0    50\n",
      "2    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 1    50\n",
      "Name: label, dtype: int64\n",
      "## 교차 검증 :3\n",
      "학습 레이블 데이터 분포:\n",
      " 0    50\n",
      "1    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 2    50\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "kfold=KFold(n_splits=3)\n",
    "n_iter=0\n",
    "for train_index,test_index in kfold.split(iris_df):\n",
    "    n_iter +=1\n",
    "    label_train=iris_df['label'].iloc[train_index]\n",
    "    label_test=iris_df['label'].iloc[test_index]\n",
    "    print('## 교차 검증 :{0}'.format(n_iter))\n",
    "    print('학습 레이블 데이터 분포:\\n', label_train.value_counts())\n",
    "    print('검증 레이블 데이터 분포:\\n', label_test.value_counts())\n",
    "    #iris_df['label'].value_counts() ??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8474e9e8",
   "metadata": {},
   "source": [
    "학습 레이블 데이터는 1,2 값이 50 개씩 있고 검증 레이블 데이터는 0값이 50개 추출 되었다. 서로 갖고 있는 값이 다르기 때문에 예측정확도는 0이 된다.\n",
    "\n",
    "----\n",
    "Stratified K 폴드는 이렇게 KFold로 분할된 레이블 데이터 세트가 전체 레이블 값의 분포도를 반영하지 못하는 문제를 해결한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ffbdaf85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 교차 검증 :1\n",
      "학습 레이블 데이터 분포:\n",
      " 0    50\n",
      "1    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 0    17\n",
      "1    17\n",
      "2    16\n",
      "Name: label, dtype: int64\n",
      "## 교차 검증 :2\n",
      "학습 레이블 데이터 분포:\n",
      " 0    50\n",
      "1    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 0    17\n",
      "2    17\n",
      "1    16\n",
      "Name: label, dtype: int64\n",
      "## 교차 검증 :3\n",
      "학습 레이블 데이터 분포:\n",
      " 0    50\n",
      "1    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 1    17\n",
      "2    17\n",
      "0    16\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf=StratifiedKFold(n_splits=3)\n",
    "n_iter=0\n",
    "\n",
    "for trian_index,test_index in skf.split(iris_df,iris_df['label']):\n",
    "    n_iter+=1\n",
    "    label_train=iris_df['label'].iloc[train_index]\n",
    "    label_test=iris_df['label'].iloc[test_index]\n",
    "    print('## 교차 검증 :{0}'.format(n_iter))\n",
    "    print('학습 레이블 데이터 분포:\\n', label_train.value_counts())\n",
    "    print('검증 레이블 데이터 분포:\\n', label_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a0519085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#1 교차 검증 정확도 :0.98, 학습 데이터 크기 :100, 검증 데이터 크기:50\n",
      "\n",
      "#1 교차 검증 세트 인덱스:[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  50\n",
      "  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115]\n",
      "\n",
      "#2 교차 검증 정확도 :0.94, 학습 데이터 크기 :100, 검증 데이터 크기:50\n",
      "\n",
      "#2 교차 검증 세트 인덱스:[ 17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  67\n",
      "  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82 116 117 118\n",
      " 119 120 121 122 123 124 125 126 127 128 129 130 131 132]\n",
      "\n",
      "#3 교차 검증 정확도 :0.98, 학습 데이터 크기 :100, 검증 데이터 크기:50\n",
      "\n",
      "#3 교차 검증 세트 인덱스:[ 34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  83  84\n",
      "  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 133 134 135\n",
      " 136 137 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      "## 교차 검증별 정확도: [0.98 0.94 0.98]\n",
      "## 평균 검증 정확도: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "df_clf=DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "skfold=StratifiedKFold(n_splits=3)\n",
    "n_iter=0\n",
    "cv_accuracy=[]\n",
    "\n",
    "for train_index,test_index in skfold.split(features,label):\n",
    "    X_train,X_test=features[train_index],features[test_index]\n",
    "    y_train,y_test=label[train_index],label[test_index]\n",
    "    #학습 및 예측\n",
    "    dt_clf.fit(X_train,y_train)\n",
    "    pred=dt_clf.predict(X_test)\n",
    "\n",
    "    #반복 시마다 정확도 측정\n",
    "    n_iter +=1\n",
    "    accuracy=np.round(accuracy_score(y_test,pred),4)\n",
    "    train_size=X_train.shape[0]\n",
    "    test_size=X_test.shape[0]\n",
    "    print('\\n#{0} 교차 검증 정확도 :{1}, 학습 데이터 크기 :{2}, 검증 데이터 크기:{3}'\n",
    "          .format(n_iter,accuracy,train_size,test_size))\n",
    "    print('\\n#{0} 교차 검증 세트 인덱스:{1}'.format(n_iter,test_index))\n",
    "    cv_accuracy.append(accuracy)\n",
    "print('\\n## 교차 검증별 정확도:',np.round(cv_accuracy,4))\n",
    "print('## 평균 검증 정확도:', np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63b0254",
   "metadata": {},
   "source": [
    "3개의 Stratified K 폴드로 교차 검증한 결과 평균 검증 정확도는 ```96.66%```로 측정됐다. 왜곡된 레이블 데이터 세트에서는 반드시 Stratified K 폴드를 이용해 교차검증을 해야한다. 일반적으로 ```분류```에서의 교차검증은 Stratified K 폴드로 분할돼야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbc6b6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
